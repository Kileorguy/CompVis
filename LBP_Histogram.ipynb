{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from skimage.feature import hog,local_binary_pattern\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV ,StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH = './Dataset/mask/'\n",
    "NO_MASK_PATH = './Dataset/no_mask/'\n",
    "\n",
    "MASK_PATH_PREPROCESSED = './PreProcessed/mask/'\n",
    "NO_MASK_PATH_PREPROCESSED = './PreProcessed/no_mask/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data = []\n",
    "no_mask_data = []\n",
    "\n",
    "for i in os.listdir(MASK_PATH_PREPROCESSED):\n",
    "    path = os.path.join(MASK_PATH_PREPROCESSED,i)\n",
    "    img = cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "    mask_data.append(img)\n",
    "   \n",
    "for i in os.listdir(NO_MASK_PATH_PREPROCESSED):\n",
    "    path = os.path.join(NO_MASK_PATH_PREPROCESSED,i)\n",
    "    img = cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "    no_mask_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_features = []\n",
    "no_masked_features = []\n",
    "\n",
    "numPoints = 24\n",
    "radius = 8\n",
    "eps=1e-7\n",
    "\n",
    "for i in mask_data:\n",
    "    lbp = local_binary_pattern(i, numPoints,radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "\t\t\tbins=np.arange(0, numPoints + 3),\n",
    "\t\t\trange=(0, numPoints + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    masked_features.append(hist)\n",
    "    \n",
    "for i in no_mask_data:\n",
    "    lbp = local_binary_pattern(i, numPoints,radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "\t\t\tbins=np.arange(0, numPoints + 3),\n",
    "\t\t\trange=(0, numPoints + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    no_masked_features.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.601013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053345</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>0.614197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052673</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.603088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053162</td>\n",
       "      <td>0.036804</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>0.629517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>0.594360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.012146</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.024597</td>\n",
       "      <td>0.490417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.036499</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.024536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>0.411621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.029602</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.025513</td>\n",
       "      <td>0.495972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.033081</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>0.509705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.043091</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.504517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1291 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.050720  0.037842  0.014893  0.011963  0.006226  0.005432  0.004517   \n",
       "1    0.053345  0.037476  0.013611  0.010803  0.010193  0.008362  0.005981   \n",
       "2    0.052673  0.041992  0.014709  0.013000  0.010559  0.006470  0.006958   \n",
       "3    0.053162  0.036804  0.013550  0.009766  0.007019  0.007324  0.006165   \n",
       "4    0.038940  0.030090  0.016296  0.012573  0.008118  0.009033  0.008362   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "637  0.045959  0.027039  0.020081  0.014282  0.014709  0.016663  0.017090   \n",
       "638  0.036499  0.027222  0.031433  0.030640  0.023926  0.020203  0.020203   \n",
       "639  0.044434  0.030701  0.029602  0.021729  0.020203  0.015625  0.015503   \n",
       "640  0.051575  0.033081  0.016418  0.016785  0.013916  0.014709  0.016479   \n",
       "641  0.043091  0.028870  0.023499  0.019714  0.015442  0.016724  0.015198   \n",
       "\n",
       "            7         8         9  ...        17        18        19  \\\n",
       "0    0.004883  0.005432  0.009155  ...  0.008850  0.007690  0.007446   \n",
       "1    0.007141  0.008545  0.009399  ...  0.006165  0.003479  0.006592   \n",
       "2    0.005981  0.006958  0.009766  ...  0.007996  0.005981  0.007812   \n",
       "3    0.004761  0.005127  0.008057  ...  0.008850  0.004272  0.006165   \n",
       "4    0.008179  0.009216  0.013611  ...  0.006470  0.004272  0.004944   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "637  0.019409  0.018982  0.019104  ...  0.013855  0.010132  0.012146   \n",
       "638  0.017273  0.017761  0.024536  ...  0.005615  0.005127  0.008789   \n",
       "639  0.016479  0.016907  0.015930  ...  0.009583  0.007507  0.006958   \n",
       "640  0.016785  0.017578  0.018372  ...  0.012939  0.008606  0.008972   \n",
       "641  0.013794  0.015259  0.019470  ...  0.008972  0.006348  0.007629   \n",
       "\n",
       "           20        21        22        23        24        25  label  \n",
       "0    0.008667  0.009644  0.010742  0.021118  0.021240  0.601013      1  \n",
       "1    0.004150  0.006104  0.010742  0.028320  0.027161  0.614197      1  \n",
       "2    0.004761  0.006592  0.011047  0.029846  0.029846  0.603088      1  \n",
       "3    0.005066  0.005371  0.007263  0.028564  0.028259  0.629517      1  \n",
       "4    0.005188  0.007080  0.010986  0.023254  0.028198  0.594360      1  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "637  0.006836  0.009399  0.012756  0.016113  0.024597  0.490417      0  \n",
       "638  0.007812  0.013550  0.023926  0.021729  0.026550  0.411621      0  \n",
       "639  0.006775  0.008545  0.014771  0.024231  0.025513  0.495972      0  \n",
       "640  0.006470  0.008423  0.010681  0.016296  0.021851  0.509705      0  \n",
       "641  0.008118  0.010742  0.012939  0.021973  0.024902  0.504517      0  \n",
       "\n",
       "[1291 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(masked_features)\n",
    "df['label'] = 1\n",
    "\n",
    "df1 = pd.DataFrame(no_masked_features)\n",
    "df1['label'] = 0\n",
    "\n",
    "merged = pd.concat([df,df1])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged['label']\n",
    "x = merged.drop(columns=['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='rbf',gamma=0.01, C=0.1)\n",
    "# svm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# cross_validation = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#               'kernel': ['rbf']}  \n",
    "  \n",
    "# grid = GridSearchCV(SVC(), param_grid, cv=cross_validation,refit = True, verbose = 3) \n",
    "  \n",
    "# grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.01)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(C= 10, gamma= 0.01, kernel= 'rbf')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       437\n",
      "           1       0.71      0.78      0.75       427\n",
      "\n",
      "    accuracy                           0.74       864\n",
      "   macro avg       0.74      0.74      0.74       864\n",
      "weighted avg       0.74      0.74      0.74       864\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70       205\n",
      "           1       0.72      0.75      0.74       222\n",
      "\n",
      "    accuracy                           0.72       427\n",
      "   macro avg       0.72      0.72      0.72       427\n",
      "weighted avg       0.72      0.72      0.72       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best_model = grid.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "ytrain_pred = classifier.predict(X_train)\n",
    "ytest_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# print(f\"Best parameters found: {grid.best_params_}\")\n",
    "# print(f\"Best cross-validation score: {grid.best_score_}\")\n",
    "\n",
    "print(classification_report(y_train, ytrain_pred))\n",
    "print(classification_report(y_test, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  56]\n",
      " [ 63 166]]\n",
      "[[304  94]\n",
      " [133 333]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matrix_kebingungan = confusion_matrix(ytest_pred, y_test)\n",
    "print(matrix_kebingungan)\n",
    "\n",
    "matrix_kebingungan = confusion_matrix(ytrain_pred, y_train)\n",
    "print(matrix_kebingungan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = cv.imread('./b.jpg', cv.IMREAD_GRAYSCALE)\n",
    "# # img = no_mask_data[-1:]\n",
    "# # print(img)\n",
    "# faces = haarcasade.detectMultiScale(img, scaleFactor = 1.2, minNeighbors = 5)\n",
    "# if not len(faces) < 1:\n",
    "#     for face_rect in faces:\n",
    "#         x, y, w, h = face_rect\n",
    "#         face_image = img[y:y+w, x:x+h]\n",
    "#         resized = cv.resize(face_image,(128,128))\n",
    "\n",
    "#         hog_feature = hog(resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys', visualize=False)\n",
    "#         test_data = pd.DataFrame(hog_feature).T\n",
    "\n",
    "#         result=best_model.predict(test_data)[0]\n",
    "#         print(result)\n",
    "#         if result == 0:\n",
    "#             result = 'No Mask'\n",
    "#         else:\n",
    "#             result = 'Mask'\n",
    "\n",
    "\n",
    "#         cv.putText(img, result, (100,100), cv.FONT_HERSHEY_PLAIN, 1.5, (255, 0, 0), 1)\n",
    "#         cv.imshow('',img)\n",
    "#         cv.waitKey(0)\n",
    "#         cv.destroyAllWindows()\n",
    "\n",
    "#         cv.imshow('',resized)\n",
    "#         cv.waitKey(0)\n",
    "#         cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21132\\156224373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./model.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Model saved to {model_filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_filename = './model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
